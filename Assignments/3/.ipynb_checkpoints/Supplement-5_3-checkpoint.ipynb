{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Programming Task: Digit recognition using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Complete the code for the ConvNet class given below using the network description from supplement pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Convolutional layer: kernel size 5x5, stride 1, 20 feature maps\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # ReLU activation\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Max pooling: pooling window 2x2, stride 2\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layer with 100 neurons\n",
    "        self.fc1 = nn.Linear(20 * 14 * 14, 100)  # 14x14 is the output size after pooling\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Final fully connected layer for 10 class probabilities\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        x = self.conv1(x)  # Convolutional layer\n",
    "        x = self.relu1(x)  # ReLU activation\n",
    "        x = self.pool1(x)  # Max pooling\n",
    "\n",
    "        # Flatten the max-pool output into a vector\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        x = self.fc1(x)  # Fully connected layer\n",
    "        x = self.relu2(x)  # ReLU activation\n",
    "        x = self.fc2(x)  # Final layer for class probabilities\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3920, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "print(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Train the CNN and observe the difference in performance in comparison to the feed-forward\n",
    "network from the task 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper parameters.\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 60000\n",
      "Testing dataset size: 10000\n",
      "Batch shape: torch.Size([64, 1, 28, 28]), Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST data set.\n",
    "# Define transformations: Convert to tensor and normalize (mean=0.5, std=0.5 for grayscale images)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST training and testing datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for batching\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print sample size for verification\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Testing dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Example: Display a batch shape from the train loader\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}, Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the loss function and the optimization criteria\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification problems\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)  # Stochastic Gradient Descent\n",
    "\n",
    "# (Optional) If using Adam optimizer\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5968\n",
      "Epoch [2/10], Loss: 0.2027\n",
      "Epoch [3/10], Loss: 0.1450\n",
      "Epoch [4/10], Loss: 0.1149\n",
      "Epoch [5/10], Loss: 0.0951\n",
      "Epoch [6/10], Loss: 0.0832\n",
      "Epoch [7/10], Loss: 0.0737\n",
      "Epoch [8/10], Loss: 0.0668\n",
      "Epoch [9/10], Loss: 0.0608\n",
      "Epoch [10/10], Loss: 0.0559\n",
      "Training complete. Model saved as 'cnn_mnist.pth'.\n"
     ]
    }
   ],
   "source": [
    "# Run the main training loop\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    net.train()  # Set the model to training mode\n",
    "    total_loss = 0  # Track the total loss for the epoch\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = net(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save the trained model (optional)\n",
    "torch.save(net.state_dict(), \"cnn_mnist.pth\")\n",
    "print(\"Training complete. Model saved as 'cnn_mnist.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.38%\n"
     ]
    }
   ],
   "source": [
    "# Run the testing loop\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradient calculation during evaluation\n",
    "        for images, labels in loader:\n",
    "            outputs = model(images)  # Forward pass\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "            total += labels.size(0)  # Total number of samples\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_accuracy = evaluate_model(net, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Calculate the number of learnable parameters and the output shape in each layer. Verify your\n",
    "answers with model summary. (Refer last cell of the tutorial notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ConvNet                                  [64, 10]                  --\n",
      "├─Conv2d: 1-1                            [64, 20, 28, 28]          520\n",
      "├─ReLU: 1-2                              [64, 20, 28, 28]          --\n",
      "├─MaxPool2d: 1-3                         [64, 20, 14, 14]          --\n",
      "├─Linear: 1-4                            [64, 100]                 392,100\n",
      "├─ReLU: 1-5                              [64, 100]                 --\n",
      "├─Linear: 1-6                            [64, 10]                  1,010\n",
      "==========================================================================================\n",
      "Total params: 393,630\n",
      "Trainable params: 393,630\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 51.25\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 8.08\n",
      "Params size (MB): 1.57\n",
      "Estimated Total Size (MB): 9.86\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the ConvNet\n",
    "#net = ConvNet()\n",
    "\n",
    "# Generate a model summary\n",
    "model_summary = summary(net, input_size=(64, 1, 28, 28))  # Batch size=64, single grayscale channel, input size=28x28\n",
    "print(model_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c617624a7fd88b4018bd9e75be0d58c4afb6a334791d511af9b9a5162b5af2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
